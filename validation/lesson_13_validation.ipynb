{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidenotes (definitions, code snippets, resources, etc.)\n",
    "- Note on data structure: list\n",
    "    - empty list has a truth value of false\n",
    "- [Feature Selection with scikit-learn for intro_to_ml](http://napitupulu-jon.appspot.com/posts/feature-selection-ud120.html)\n",
    "    - Looks very helpful for copying notes, course materials\n",
    "    - Investigate meaning of `# %%writefile new_enron_feature.py` inserted at top of edited studentMain.py module\n",
    "\n",
    "### ML Order of Operations\n",
    "![order of operations](lesson_13_images/ml_order_of_operations.png)\n",
    "\n",
    "### Python 3 change\n",
    "- From Python 3.3, dict keys are iterating through in a random order for each iteration (will alter GridSearchCV's output).\n",
    "    - See note with validation mini-project for info on coverting code from 2.7 to 3.3.\n",
    "\n",
    "\n",
    "### Python 2\n",
    "```python\n",
    "### there can be many \"to\" emails, but only one \"from\", so the\n",
    "### \"to\" processing needs to be a little more complicated\n",
    "# uses counter for iterating through, duplicates process for cc_emails\n",
    "#   does not seem very pythonic, but maybe clearest method\n",
    "if to_emails:\n",
    "    ctr = 0  # counter for iterating through, perhaps not pythonic\n",
    "    while not to_poi and ctr < len(to_emails):\n",
    "        if to_emails[ctr] in poi_email_list:\n",
    "            to_poi = True\n",
    "        ctr += 1\n",
    "```\n",
    "\n",
    "### Useful git code snippets\n",
    "- `git reset --soft HEAD~`\n",
    "    - Leaves working tree as it was before git commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "sklearn User Guide [3.1. Cross-validation: evaluating estimator performance](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "- Used to determine optimal split of testing and training data\n",
    "- see video for explanation\n",
    "\n",
    "## KFold in sklearn\n",
    "- Does not randomize data automatically (can cause issues with performance)\n",
    "- Use keyword argument `shuffle=True` to randomized events.\n",
    "\n",
    "## GridSearchCV in sklearn\n",
    "`sklearn.grid_search`.GridSearchCV [Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and [User Guide](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "Example from documentation, explained:\n",
    "```\n",
    "from sklearn import svm, grid_search, datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "- `parameters` is a dict of different sets of parameters that will be used to train multiple SVM classifiers.\n",
    "- `svr = svm.SVC()` is passed to the GridSearchCV classifier to indicate what classifier iterate.\n",
    "- `clf = grid_search.GridSearchCV(svr, parameters)` creates the classifier by generating a 'grid' of SMVs from each of the given combinations of values for (kernel, C).\n",
    "- `clf.fit(iris.data, iris.target)` iterates through the grid, returning a fitted classifier automatically tuned to the optimal parameter combination. \n",
    "    - `clf.best_params_` returns those parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the eigenfaces code, which you can find here. What parameters of the SVM are being tuned with GridSearchCV?\n",
    "\n",
    "- _Answer:_ 5 values of C and 6 values of gamma are tested out.\n",
    "\n",
    "## Mini-project! on validation\n",
    "You’ll start by building the simplest imaginable (unvalidated) POI identifier. The starter code (validation/validate_poi.py) for this lesson is pretty bare--all it does is read in the data, and format it into lists of labels and features. Create a decision tree classifier (just use the default parameters), train it on all the data (you will fix this in the next part!), and print out the accuracy. THIS IS AN OVERFIT TREE, DO NOT TRUST THIS NUMBER! Nonetheless, what’s the accuracy?\n",
    "\n",
    "- _Answer:_ 0.98947368421052628. \n",
    "    - \"Pretty high accuracy, huh?  Yet another case where testing on the training data would make you think you were doing amazingly well, but as you already know, that's exactly what holdout test data is for...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98947368421052628"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validate_poi import *\n",
    "\n",
    "### it's all yours from here forward! \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features, labels)\n",
    "pred = clf.predict(features)\n",
    "accuracy_score(pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’ll add in training and testing, so that you get a trustworthy accuracy number. Use the train_test_split validation available in sklearn.cross_validation; \n",
    "- hold out 30% of the data for testing and \n",
    "- set the random_state parameter to 42 (random_state controls which points go into the training set and which are used for testing; setting it to 42 means we know exactly which events are in which set, and can check the results you get). \n",
    "\n",
    "What’s your updated accuracy?\n",
    "\n",
    "- _Answer:_ 0.72413793103448276\n",
    "    - Properly deployed with \"testing data brings us back down to earth after that 99% accuracy in the last quiz.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72413793103448276"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validate_poi import *\n",
    "\n",
    "### it's all yours from here forward! \n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score    \n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy_score(pred, labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
